{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f573ceec-1833-49fc-9235-b7eb80be462d",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051ae91d-6c72-4f10-b74f-c18181c38e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc194028-7679-48b9-8b12-ef37e3507194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 19:49:05.087927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b900eb84-9fdc-4f52-b17d-31a1fc7d07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'lemmatizer', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e700ec4-63cb-4fe6-b7de-05ed26f0129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0301bc98-a787-4275-ada7-e9f214b87e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db959cb1-a6eb-4529-a5fb-a9d88385ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('../06-Deep-Learning/moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09e0314f-76b9-4e2e-9786-e8aaa0f16351",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "351f97d6-c82d-4284-a37c-d5beb2697535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11338"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4959cf9a-d66b-4740-9c10-b5ee4f89a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing 25 words --> network predicts #26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89f28c9a-3782-42ee-b442-d7be3e0de439",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58218577-8c5f-4173-b2c9-2d7ce688bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i - train_len: i]\n",
    "\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a49ad62-993b-4b5c-9bc9-480c6df6f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2ae5f4f-2858-4b67-965e-562a6ccd0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bacd341-e4e6-4262-88c6-2d928171009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33f6d744-7839-4409-bed8-560f20e5a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a944203a-59b9-47b0-861f-26d56fb83911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2718"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1590c5fe-b43f-473c-801b-a98a03b21612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27fc8009-6c30-42c7-9541-10cd1d73969c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaeefe5d-0cf8-4e73-b001-627c7c52209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51f6d864-47de-409d-9443-80839b900e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21c9bdf3-748b-483c-9901-f05609e7d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72c78b89-54da-4a8e-8960-70e948482111",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocabulary_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caf78b07-4d66-44c4-9188-8520378eb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c72580d9-cc72-4bb8-8965-cd820345a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02d84bdb-d145-4556-a061-257b7e23e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, seq_len, input_length=seq_len))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "012ecc86-5bba-4400-9130-73fb22af1840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 25, 25)            67975     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 25, 50)            15200     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2719)              138669    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,594\n",
      "Trainable params: 244,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aebaa55f-95a3-49f4-9b59-2d751dd38c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fb19c47-c1ee-4111-85d0-5cd18a2ce004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 6.3461 - accuracy: 0.0529\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 6.3309 - accuracy: 0.0529\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 2s 25ms/step - loss: 6.2492 - accuracy: 0.0529\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 2s 25ms/step - loss: 6.1480 - accuracy: 0.0529\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 6.0954 - accuracy: 0.0529\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 6.0561 - accuracy: 0.0529\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 6.0086 - accuracy: 0.0545\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 5.9318 - accuracy: 0.0595\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 5.8568 - accuracy: 0.0617\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 5.8049 - accuracy: 0.0644\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 5.7511 - accuracy: 0.0655\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 5.6825 - accuracy: 0.0666\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 5.6280 - accuracy: 0.0715\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 5.5842 - accuracy: 0.0705\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 5.5485 - accuracy: 0.0713\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 5.5173 - accuracy: 0.0737\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 5.4914 - accuracy: 0.0728\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 5.4625 - accuracy: 0.0768\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 5.4364 - accuracy: 0.0740\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 5.4086 - accuracy: 0.0757\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 5.3842 - accuracy: 0.0790\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 5.3561 - accuracy: 0.0774\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 5.3216 - accuracy: 0.0794\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 2s 28ms/step - loss: 5.2818 - accuracy: 0.0806\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 3s 28ms/step - loss: 5.2448 - accuracy: 0.0825\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 5.2062 - accuracy: 0.0835\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 5.1696 - accuracy: 0.0865\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 3s 28ms/step - loss: 5.1367 - accuracy: 0.0871\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 5.1043 - accuracy: 0.0874\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 5.0751 - accuracy: 0.0892\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 5.0454 - accuracy: 0.0895\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 5.0133 - accuracy: 0.0900\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 4.9857 - accuracy: 0.0895\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 4.9569 - accuracy: 0.0920\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.9225 - accuracy: 0.0937\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 4.8955 - accuracy: 0.0911\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.8623 - accuracy: 0.0941\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 4.8323 - accuracy: 0.0967\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.7973 - accuracy: 0.0984\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.7689 - accuracy: 0.0995\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.7356 - accuracy: 0.1010\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.7061 - accuracy: 0.1025\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 3s 33ms/step - loss: 4.6756 - accuracy: 0.1068\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.6461 - accuracy: 0.1096\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 3s 34ms/step - loss: 4.6210 - accuracy: 0.1101\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 3s 33ms/step - loss: 4.5953 - accuracy: 0.1114\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.5624 - accuracy: 0.1124\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.5393 - accuracy: 0.1155\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.5077 - accuracy: 0.1170\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.4800 - accuracy: 0.1208\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 4.4500 - accuracy: 0.1203\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.4256 - accuracy: 0.1223\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 4.3996 - accuracy: 0.1241\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 4.3711 - accuracy: 0.1258\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.3406 - accuracy: 0.1279\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.3103 - accuracy: 0.1311\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.2841 - accuracy: 0.1323\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.2536 - accuracy: 0.1340\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.2302 - accuracy: 0.1359\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.2011 - accuracy: 0.1390\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.1719 - accuracy: 0.1397\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 3s 32ms/step - loss: 4.1398 - accuracy: 0.1405\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.1128 - accuracy: 0.1415\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 3s 33ms/step - loss: 4.0848 - accuracy: 0.1473\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 4.0536 - accuracy: 0.1468\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 3s 33ms/step - loss: 4.0315 - accuracy: 0.1528\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 3s 33ms/step - loss: 4.0060 - accuracy: 0.1532\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 3s 36ms/step - loss: 3.9797 - accuracy: 0.1544\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 3s 36ms/step - loss: 3.9430 - accuracy: 0.1596\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3.9140 - accuracy: 0.1607\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 3s 36ms/step - loss: 3.8870 - accuracy: 0.1654\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 3s 36ms/step - loss: 3.8612 - accuracy: 0.1685\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 3s 36ms/step - loss: 3.8303 - accuracy: 0.1689\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 3s 34ms/step - loss: 3.7989 - accuracy: 0.1739\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3.7729 - accuracy: 0.1775\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 3s 39ms/step - loss: 3.7452 - accuracy: 0.1835\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 3s 37ms/step - loss: 3.7169 - accuracy: 0.1841\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3.6882 - accuracy: 0.1869\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3.6588 - accuracy: 0.1970\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 3.6336 - accuracy: 0.1970\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 3s 37ms/step - loss: 3.6073 - accuracy: 0.2039\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 3.5879 - accuracy: 0.2050\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 3.5495 - accuracy: 0.2106\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 3.5227 - accuracy: 0.2110\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 3.5023 - accuracy: 0.2121\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 3.4797 - accuracy: 0.2237\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 3.4500 - accuracy: 0.2245\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 3.4302 - accuracy: 0.2298\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 3.4007 - accuracy: 0.2371\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3.3779 - accuracy: 0.2407\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3.3438 - accuracy: 0.2451\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3.3254 - accuracy: 0.2451\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 3.3037 - accuracy: 0.2525\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 3.2780 - accuracy: 0.2535\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 3.2563 - accuracy: 0.2580\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 3.2366 - accuracy: 0.2650\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 3.2111 - accuracy: 0.2710\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 3.1854 - accuracy: 0.2729\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 3s 39ms/step - loss: 3.1664 - accuracy: 0.2728\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 3s 39ms/step - loss: 3.1367 - accuracy: 0.2832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbdae7c8b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8a89ada-2097-4bc4-ad94-9851620e097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_moby_dick_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ff955fd-a4da-4cb8-9302-b09e8515c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer, open('my_simple_tokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d545455-4e87-4dbd-9eb2-a287fbfe0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce0a51-a857-4b70-acb8-8392376d099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ad94494-9c4d-4323-be45-cd765e4fe4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    input_text = seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        pred_word_ind = np.argmax(model.predict(pad_encoded, verbose=0))\n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        input_text += ' ' + pred_word\n",
    "        output_text.append(pred_word)\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2db171d2-fee8-486f-bcfe-6be383bb8b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0, len(text_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "070cea30-51cd-4db1-a833-1249fe2ce01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"thought i to myself the man 's a human being just as i am he has just as much reason to fear me as i have\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed_text = text_sequences[random_pick]\n",
    "' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0afb1381-5b63-46c8-a0c0-785ebddae4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b e e n   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t   n o t'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = generate_text(model, tokenizer, seq_len, random_seed_text, 25)\n",
    "' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa85659-6d94-4ae2-9ebc-5ecc7a3d2161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
